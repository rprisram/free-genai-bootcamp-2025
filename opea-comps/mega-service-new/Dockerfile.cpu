FROM python:3.10-slim

WORKDIR /app

# Install build dependencies
RUN apt-get update && apt-get install -y \
    build-essential \
    git \
    cmake \
    ninja-build \
    && rm -rf /var/lib/apt/lists/*

# Set environment variables for CPU-only build
ENV VLLM_TARGET_DEVICE=cpu
ENV VLLM_USE_CPU_ONLY=1
ENV VLLM_DEVICE=cpu

# Copy requirements and install dependencies
COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt

# Clone the repository
RUN git clone https://github.com/vllm-project/vllm.git

# Copy all requirements files to a known location
RUN mkdir -p /requirements
RUN cp ./vllm/requirements/*.txt /requirements/

# Fix paths in requirements files
RUN sed -i 's|-r |-r /requirements/|g' /requirements/cpu.txt

RUN pip install "cmake>=3.26" wheel packaging ninja "setuptools-scm>=8" numpy
# Install from the copied location
RUN pip install -r /requirements/cpu.txt --extra-index-url https://download.pytorch.org/whl/cpu

# Change to the vllm directory before installing
WORKDIR /app/vllm
# Then install vLLM
RUN VLLM_TARGET_DEVICE=cpu python setup.py install

# Expose the port
EXPOSE 8000

# Set command to run the vLLM server
CMD ["python", "-m", "vllm.entrypoints.openai.api_server", "--model", "llama3.2:1b", "--device", "cpu"]
